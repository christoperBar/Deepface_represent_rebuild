{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1575ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742bf6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Documents\\Magang\\Extracted-Model\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Union, Optional\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Import model Facenet512\n",
    "from facenetlib.Facenet_standalone import InceptionResNetV1\n",
    "\n",
    "# Import RetinaFace detector\n",
    "from retina import detect_faces, create_retinaface_model\n",
    "\n",
    "# Import preprocessing utils DeepFace\n",
    "from facenetlib import preprocessing, image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53d98cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Documents\\Magang\\Extracted-Model\\.venv\\lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Documents\\Magang\\Extracted-Model\\.venv\\lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "‚úÖ Model Facenet512 berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Load model embedding\n",
    "# =========================\n",
    "model = InceptionResNetV1(dimension=512)\n",
    "model.load_weights(\"facenetlib/facenet512_weights.h5\")  # sesuaikan path jika perlu\n",
    "print(\"‚úÖ Model Facenet512 berhasil dimuat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50a38f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building RetinaFace model architecture...\n",
      "Loading weights into model...\n",
      "Weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Load model detect\n",
    "# =========================\n",
    "modeld = create_retinaface_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7561f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∑ Memproses: IMG_2042.jpg\n",
      "üì∑ Memproses: WhatsApp Image 2025-07-30 at 16.57.34.jpeg\n",
      "üì∑ Memproses: WhatsApp Image 2025-07-30 at 16.57.37.jpeg\n",
      "üì∑ Memproses: WhatsApp Image 2025-07-30 at 16.57.47.jpeg\n",
      "üì∑ Memproses: WhatsApp Image 2025-07-30 at 16.57.48.jpeg\n",
      "‚úÖ Embeddings disimpan di embedding/embeddings.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# Represent function\n",
    "# mirip representation.py\n",
    "# =========================\n",
    "def represent(\n",
    "    img_path: Union[str, np.ndarray],\n",
    "    enforce_detection: bool = True,\n",
    "    align: bool = True,\n",
    "    expand_percentage: int = 0,\n",
    "    normalization: str = \"base\",\n",
    "    threshold: float = 0.9\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Ekstraksi embedding wajah menggunakan RetinaFace sebagai detektor.\n",
    "    Output format mirip DeepFace `represent`.\n",
    "    \"\"\"\n",
    "    resp_objs = []\n",
    "\n",
    "    # Load gambar (RGB)\n",
    "    img, _ = image_utils.load_image(img_path)\n",
    "    if img.shape[2] == 3:\n",
    "        img_bgr = img[:, :, ::-1]  # ubah urutan channel\n",
    "    else:\n",
    "        img_bgr = img\n",
    "    # Deteksi wajah\n",
    "    detections = detect_faces(\n",
    "        img_path=img_bgr,\n",
    "        threshold=threshold,\n",
    "        model=modeld\n",
    "    )\n",
    "    \n",
    "    if isinstance(detections, dict) and all(isinstance(v, dict) for v in detections.values()):\n",
    "        detections = list(detections.values())\n",
    "\n",
    "    # Pastikan list of dict\n",
    "    if not isinstance(detections, list) or not all(isinstance(d, dict) for d in detections):\n",
    "        raise ValueError(f\"Format hasil detect_faces tidak valid: {type(detections)}\")\n",
    "\n",
    "    if enforce_detection and len(detections) == 0:\n",
    "        raise ValueError(f\"Tidak ada wajah terdeteksi pada {img_path}\")\n",
    "\n",
    "    for det in detections:\n",
    "        coords = det.get(\"facial_area\")\n",
    "        if isinstance(coords, list) and len(coords) == 4:\n",
    "            x1, y1, x2, y2 = coords\n",
    "            facial_area = {\n",
    "                \"x\": int(x1),\n",
    "                \"y\": int(y1),\n",
    "                \"w\": int(x2 - x1),\n",
    "                \"h\": int(y2 - y1)\n",
    "            }\n",
    "        elif isinstance(coords, dict):\n",
    "            facial_area = coords\n",
    "        else:\n",
    "            raise ValueError(f\"Format facial_area tidak valid: {coords}\")\n",
    "\n",
    "        confidence = det.get(\"confidence\") or det.get(\"score\", 0.0)\n",
    "\n",
    "        # Crop wajah\n",
    "        face_img = img[\n",
    "            facial_area[\"y\"]: facial_area[\"y\"] + facial_area[\"h\"],\n",
    "            facial_area[\"x\"]: facial_area[\"x\"] + facial_area[\"w\"]\n",
    "        ]\n",
    "        # Resize untuk Facenet\n",
    "        face_img = preprocessing.resize_image(face_img, target_size=(160, 160))\n",
    "\n",
    "        # Normalisasi sesuai Facenet\n",
    "        face_img = preprocessing.normalize_input(face_img, normalization=normalization)\n",
    "\n",
    "        # Pastikan shape input (1, 160, 160, 3)\n",
    "        if face_img.ndim == 3:\n",
    "            face_img = np.expand_dims(face_img, axis=0)\n",
    "        elif face_img.ndim == 4 and face_img.shape[0] == 1:\n",
    "            pass  # sudah batch dim\n",
    "        else:\n",
    "            raise ValueError(f\"Bentuk input tidak dikenali: {face_img.shape}\")\n",
    "\n",
    "        # Forward pass\n",
    "        embedding = model.predict(face_img, verbose=0)[0]\n",
    "\n",
    "        resp_objs.append({\n",
    "            \"embedding\": embedding.astype(float).tolist(),\n",
    "            \"facial_area\": facial_area,\n",
    "            \"face_confidence\": confidence\n",
    "        })\n",
    "\n",
    "    return resp_objs\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Contoh penggunaan\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"images\"  # ganti dengan path folder kamu\n",
    "    output_json = \"embedding/embeddings.json\"\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            print(f\"üì∑ Memproses: {filename}\")\n",
    "            try:\n",
    "                results = represent(img_path)\n",
    "                # Ambil embedding wajah pertama (kalau ada banyak wajah bisa disesuaikan)\n",
    "                embeddings_dict[filename] = results[0][\"embedding\"] if results else None\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Gagal memproses {filename}: {e}\")\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(embeddings_dict, f, indent=2)\n",
    "\n",
    "    print(f\"‚úÖ Embeddings disimpan di {output_json}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
