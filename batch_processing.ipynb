{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae19d256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Documents\\Magang\\Extracted-Model\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List, Union\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24a706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facenet512\n",
    "from facenetlib.Facenet_standalone import InceptionResNetV1\n",
    "# RetinaFace\n",
    "from retina import detect_faces, create_retinaface_model\n",
    "# Preprocessing utils\n",
    "from facenetlib import preprocessing, image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a41866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Facenet512...\n",
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Documents\\Magang\\Extracted-Model\\.venv\\lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\chris\\OneDrive\\Documents\\Magang\\Extracted-Model\\.venv\\lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "[INFO] Loading RetinaFace...\n",
      "Building RetinaFace model architecture...\n",
      "Loading weights into model...\n",
      "Weights loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Load Models\n",
    "# =========================\n",
    "print(\"[INFO] Loading Facenet512...\")\n",
    "embedder = InceptionResNetV1(dimension=512)\n",
    "embedder.load_weights(\"facenetlib/facenet512_weights.h5\")\n",
    "\n",
    "print(\"[INFO] Loading RetinaFace...\")\n",
    "detector = create_retinaface_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8fd81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Batch Processing Function\n",
    "# =========================\n",
    "def batch_represent(\n",
    "    img_paths: List[str],\n",
    "    threshold: float = 0.9,\n",
    "    normalization: str = \"base\"\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Deteksi semua wajah dari setiap gambar, proses embedding dalam batch,\n",
    "    dan return hasil per file.\n",
    "    \"\"\"\n",
    "    all_faces = []   # semua crop wajah (siap masuk model)\n",
    "    meta = []        # mapping embedding -> filename + info wajah\n",
    "\n",
    "    # 1. Baca semua gambar\n",
    "    imgs_rgb = []\n",
    "    imgs_bgr = []\n",
    "    for p in img_paths:\n",
    "        img_rgb, _ = image_utils.load_image(p)\n",
    "        imgs_rgb.append(img_rgb)\n",
    "        imgs_bgr.append(img_rgb[:, :, ::-1])  # BGR untuk detektor\n",
    "\n",
    "    # 2. Deteksi wajah & kumpulkan semua crop\n",
    "    for idx, (img_path, img_bgr, img_rgb) in enumerate(zip(img_paths, imgs_bgr, imgs_rgb)):\n",
    "        detections = detect_faces(\n",
    "            img_path=img_bgr,\n",
    "            threshold=threshold,\n",
    "            model=detector\n",
    "        )\n",
    "\n",
    "        # Pastikan format list of dict\n",
    "        if isinstance(detections, dict) and all(isinstance(v, dict) for v in detections.values()):\n",
    "            detections = list(detections.values())\n",
    "\n",
    "        for det in detections:\n",
    "            coords = det[\"facial_area\"]\n",
    "            if isinstance(coords, list):\n",
    "                x1, y1, x2, y2 = coords\n",
    "            else:  # dict\n",
    "                x1, y1 = coords[\"x\"], coords[\"y\"]\n",
    "                x2, y2 = x1 + coords[\"w\"], y1 + coords[\"h\"]\n",
    "\n",
    "            face_conf = det.get(\"confidence\", det.get(\"score\", 0.0))\n",
    "            crop = img_rgb[int(y1):int(y2), int(x1):int(x2)]\n",
    "\n",
    "            # Resize & normalize\n",
    "            crop_resized = preprocessing.resize_image(crop, target_size=(160, 160))\n",
    "            crop_norm = preprocessing.normalize_input(crop_resized, normalization=normalization)\n",
    "\n",
    "            if crop_norm.ndim == 4 and crop_norm.shape[0] == 1:\n",
    "                crop_norm = crop_norm[0]\n",
    "\n",
    "            all_faces.append(crop_norm)\n",
    "            meta.append({\n",
    "                \"filename\": os.path.basename(img_path),\n",
    "                \"facial_area\": {\n",
    "                    \"x\": int(x1), \"y\": int(y1),\n",
    "                    \"w\": int(x2 - x1), \"h\": int(y2 - y1)\n",
    "                },\n",
    "                \"confidence\": float(face_conf)\n",
    "            })\n",
    "\n",
    "    if not all_faces:\n",
    "        return {}\n",
    "\n",
    "    # 3. Convert ke batch array\n",
    "    batch_faces = np.array(all_faces)\n",
    "    print(f\"[INFO] Processing {len(batch_faces)} faces in batch...\")\n",
    "\n",
    "    # 4. Sekali forward pass ke Facenet\n",
    "    embeddings = embedder.predict(batch_faces, verbose=0)\n",
    "\n",
    "    # 5. Kelompokkan hasil per file\n",
    "    results_by_file = {}\n",
    "    for m, emb in zip(meta, embeddings):\n",
    "        m[\"embedding\"] = emb.astype(float).tolist()\n",
    "        results_by_file.setdefault(m[\"filename\"], []).append(m)\n",
    "\n",
    "    return results_by_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d42af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing 9 faces in batch...\n",
      "✅ Batch embeddings saved to embedding/embeddings_batch.json\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Contoh penggunaan\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"images\"\n",
    "    output_json = \"embedding/embeddings_batch.json\"\n",
    "\n",
    "    img_files = [\n",
    "        os.path.join(input_folder, f)\n",
    "        for f in os.listdir(input_folder)\n",
    "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "\n",
    "    results = batch_represent(img_files)\n",
    "\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"✅ Batch embeddings saved to {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
